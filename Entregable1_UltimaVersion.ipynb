{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wf7K4FACL8c"
      },
      "source": [
        "#Entregable1- IRN\n",
        "###Grupo 3\n",
        "##Codigo de Generacion de Dataset\n",
        "###Integrantes:\n",
        "Diego Vasquez\n",
        "\n",
        "Fabricio Guerrero"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Codigo de Generación de Dataset\n"
      ],
      "metadata": {
        "id": "QgvDDdrnvaGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Primera Parte:\n",
        "#### En esta parte se instalan e importan las libreías necesarias para el correcto funcionamiento del código, así como también se definen las rutas de archivos de interés."
      ],
      "metadata": {
        "id": "c00QBWpiqCWP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Osjl9kwyDFzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383f72b5-d392-4f10-d859-72e6fe99ddc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/content/IRN/Entregable1/requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install -r /content/IRN/Entregable1/requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p3ve9Wj2E2Oc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "b569ece0-7a46-43b9-8b6e-9a5238691249"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-59848b110696>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_summarize_chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import PyPDF2\n",
        "import os\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "rutaTexto=r\"/DataTexto\"\n",
        "pytesseract.pytesseract.tesseract_cmd = R\"/content/IRN/Entregable1/tesseract.exe\"\n",
        "load_dotenv(find_dotenv(),override = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzcM5Ge5h7jp"
      },
      "source": [
        "Transformacion de archivos de PDF Y PNG a TXT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segunda parte:\n",
        "#### Utilización de pytesseract y PyPDF2 para la transformación de archivos .PNG y .PDF a archivos .txt"
      ],
      "metadata": {
        "id": "6PRlbGW-rlko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXXWubKKh7jp"
      },
      "outputs": [],
      "source": [
        "#Convierte los archivos PNGs a texto.\n",
        "def IMGtoText(ruta_img,caso_id):\n",
        "    imagen= Image.open(ruta_img)\n",
        "    texto= pytesseract.image_to_string(imagen)\n",
        "\n",
        "    #Crea la ruta del archivo donde se almacena el texto plano.\n",
        "    carpeta, nombre_txt = os.path.split(ruta_img)\n",
        "    nombre_txt = caso_id +\"_\" + os.path.splitext(nombre_txt)[0] + \"_SEGUIMIENTO_EXPEDIENTE.txt\"\n",
        "\n",
        "\n",
        "    ruta_txt = os.path.join(carpeta, nombre_txt)\n",
        "\n",
        "    with open(ruta_txt, 'w') as archivo:\n",
        "        archivo.write(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4PdAOHMh7jp"
      },
      "outputs": [],
      "source": [
        "#Convierte los archivos PDFs a texto.\n",
        "def PDFtoText(ruta_pdf,caso_id):\n",
        "    pdf= open(ruta_pdf,\"rb\")\n",
        "    reader= PyPDF2.PdfReader(pdf)\n",
        "    extract_info= \"\"\n",
        "    for num in range(len(reader.pages)):\n",
        "        info_page = reader._get_page(num)\n",
        "        extract_info= extract_info + info_page.extract_text()\n",
        "\n",
        "    #Crea la ruta del archivo donde se almacena el texto plano.\n",
        "    carpeta, nombre_pdf = os.path.split(ruta_pdf)\n",
        "    nombre_txt = caso_id +\"_\" + os.path.splitext(nombre_pdf)[0] + \".txt\"\n",
        "\n",
        "    ruta_txt = os.path.join(carpeta, nombre_txt)\n",
        "\n",
        "    if extract_info != \"\":\n",
        "        with open(ruta_txt, 'w') as archivo:\n",
        "            archivo.write(extract_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLwrl_X7h7jq"
      },
      "outputs": [],
      "source": [
        "def DeterminarID(string):\n",
        "    indice = 0\n",
        "    # Elimina los valores iniciales no numéricos del nombre, como 'exp', etc.\n",
        "    while indice < len(string) and not string[indice].isdigit():\n",
        "        indice += 1\n",
        "    string = string[indice:]\n",
        "    #Dado que el nombre del archivo incluye el estado, se puede obtener el estado de manera deterministica.\n",
        "    #Este estado deterministico será utilizado solamente para hallar la metrica accuracy\n",
        "    id_code, estado = string.rsplit('-', 1)\n",
        "    return id_code,estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soOpbV1Ih7jq"
      },
      "outputs": [],
      "source": [
        "def ProcesarCarpeta(rutaPrimaria, nombre_carpeta):\n",
        "    ruta_carpeta_completa = os.path.join(rutaPrimaria, nombre_carpeta)\n",
        "    lista_archivos = os.listdir(ruta_carpeta_completa)\n",
        "\n",
        "    for nombre_archivo in lista_archivos:\n",
        "        ruta_archivo = os.path.join(ruta_carpeta_completa, nombre_archivo)\n",
        "        caso_id, estado= DeterminarID(nombre_carpeta)\n",
        "        if ruta_archivo.lower().endswith('.pdf'):\n",
        "            try:\n",
        "                PDFtoText(ruta_archivo,caso_id)\n",
        "                print('Se convirtio PDF')\n",
        "            except Exception as e:\n",
        "                print(f\"Error al convertir el PDF: {e}\")\n",
        "\n",
        "        elif ruta_archivo.lower().endswith('.png'):\n",
        "            IMGtoText(ruta_archivo,caso_id)\n",
        "            print('Se convirtio Imagen')\n",
        "\n",
        "        else:\n",
        "            print(f\"{nombre_archivo} no es ni PDF ni imagen\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgMxZvGyh7jq"
      },
      "outputs": [],
      "source": [
        "#En esta celda, se corren las funciones de manera adecuada para lograr obtener los archivos en texto plano\n",
        "rutaTexto= rutaTexto\n",
        "lista_carpeta = [nombre for nombre in os.listdir(rutaTexto) if os.path.isdir(os.path.join(rutaTexto, nombre))]\n",
        "for carpeta in lista_carpeta:\n",
        "    ruta = os.path.join(rutaTexto,carpeta)\n",
        "    lista_carpetas = os.listdir(ruta)\n",
        "    for nombre in lista_carpetas:\n",
        "        ProcesarCarpeta(ruta, nombre)\n",
        "        ruta_expediente= os.path.join(ruta,nombre)\n",
        "\n",
        "    # Imprimir\n",
        "    print(\"Lista de nombres de carpetas:\")\n",
        "    print(lista_carpetas)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tercera Parte:\n",
        "#### Se utilizan modelos de LLM, a los cuales se les darán los archivos y ciertos prompts, para obtener el overview y el estado del caso."
      ],
      "metadata": {
        "id": "gWsdiO4ysd4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S969x-a8h7jq"
      },
      "outputs": [],
      "source": [
        "def ia(texto, humanInput):\n",
        "    llm  = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
        "    docs = [Document(page_content=texto)]\n",
        "\n",
        "    template = humanInput + '''\n",
        "    del siguiente texto:\n",
        "    TEXTO:{text}.\n",
        "    '''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=['text'],\n",
        "        template=template\n",
        "    )\n",
        "    chain = load_summarize_chain(\n",
        "        llm,\n",
        "        chain_type='stuff',\n",
        "        prompt=prompt,\n",
        "        verbose=False\n",
        "    )\n",
        "    resumen = chain.run(docs)\n",
        "    print(resumen)\n",
        "    return resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ_v3tPwh7jr"
      },
      "source": [
        "Ahora, se probaran distintos promts, ademas de distintas formas de introducir la data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50UQWo6Kh7jr"
      },
      "source": [
        "El primer método de introducir la información es combinando toda la info en un solo string y dándosela de frente a la IA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mfVcpZMh7jr"
      },
      "outputs": [],
      "source": [
        "def IA1(rutaExpediente,resumenPrompt,estadoPrompt):\n",
        "    texto_ia= \"\"\n",
        "    for archivo in os.listdir(rutaExpediente):\n",
        "        if archivo.lower().endswith(\".txt\"):  # Asegúrate de que solo estés leyendo archivos .txt\n",
        "            ruta_archivo = os.path.join(rutaExpediente, archivo)\n",
        "            with open(ruta_archivo, 'r') as file:\n",
        "                contenido = file.read()\n",
        "                texto_ia += contenido  # Agregar el contenido de cada archivo a la variable de texto combinado\n",
        "\n",
        "# Imprimir o hacer cualquier operación que necesites con el texto combinado\n",
        "    overview = ia(texto_ia,resumenPrompt)\n",
        "    estado= ia(texto_ia,estadoPrompt)\n",
        "    return overview, estado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRYARRA3h7jr"
      },
      "source": [
        "El segundo método es darle a la IA archivo por archivo, que saque un resumen por archivo y lo una formando una string, y finalmente sacar un resumen de dicha string unida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWB-okU-h7jr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def IA2(rutaExpediente,resumenPrompt,estadoPrompt):\n",
        "\n",
        "    overview= \"\"\n",
        "    estado= \"\"\n",
        "    for archivo in os.listdir(rutaExpediente):\n",
        "        if archivo.lower().endswith(\".txt\"):  # Asegúrate de que solo estés leyendo archivos .txt\n",
        "            ruta_archivo = os.path.join(rutaExpediente, archivo)\n",
        "            with open(ruta_archivo, 'r') as file:\n",
        "                texto_ia = file.read()\n",
        "            overview= overview + ia(texto_ia,resumenPrompt)\n",
        "            estado= estado+ ia(texto_ia,estadoPrompt)\n",
        "            print(\"_________________________________________________\")\n",
        "\n",
        "\n",
        "    overview= ia(overview,resumenPrompt)\n",
        "    estado= ia(estado,estadoPrompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m4o9MqIh7jr"
      },
      "source": [
        "El tercer método es un método regresivo, lo que hace es que cada resumen lo introduce nuevamente junto al siguiente archivo no resumido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn5OGxIZLPia"
      },
      "outputs": [],
      "source": [
        "def IA3(rutaExpediente,resumenPrompt,estadoPrompt):\n",
        "\n",
        "    overview= \"\"\n",
        "    estado= \"\"\n",
        "    for archivo in os.listdir(rutaExpediente):\n",
        "        if archivo.lower().endswith(\".txt\"):  # Asegúrate de que solo estés leyendo archivos .txt\n",
        "            ruta_archivo = os.path.join(rutaExpediente, archivo)\n",
        "            with open(ruta_archivo, 'r') as file:\n",
        "                overview = overview + file.read()\n",
        "                estado= estado + file.read()\n",
        "            overview= ia(overview,resumenPrompt)\n",
        "            estado= ia(estado,estadoPrompt)\n",
        "            print(\"_________________________________________________\")\n",
        "\n",
        "    print(\"Finalizado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u386vWDPh7jr"
      },
      "outputs": [],
      "source": [
        "def Escritura(ruta,caso_id, overview, estado,estado_deterministico):\n",
        "    #Generamos la Ruta de la carpeta.\n",
        "    if not os.path.exists(ruta):\n",
        "        os.makedirs(ruta)\n",
        "    carpeta = \"Archivos_IA_\"+caso_id\n",
        "    ruta_carpeta = os.path.join(ruta, carpeta)\n",
        "    if not os.path.exists(ruta_carpeta):\n",
        "        os.makedirs(ruta_carpeta)\n",
        "\n",
        "    #Generamos la ruta de los archivos.\n",
        "    ruta_overview = os.path.join(ruta_carpeta,caso_id+ \"_overview.txt\")\n",
        "    ruta_estado = os.path.join(ruta_carpeta, caso_id+ \"_estado.txt\")\n",
        "    ruta_estado_deterministico = os.path.join(ruta_carpeta, caso_id+ \"_estado_deterministico.txt\")\n",
        "\n",
        "\n",
        "    #Crear los archivos\n",
        "    with open(ruta_overview, 'w') as archivo:\n",
        "        archivo.write(overview)\n",
        "    with open(ruta_estado, 'w') as archivo:\n",
        "        archivo.write(estado)\n",
        "    with open(ruta_estado_deterministico, 'w') as archivo:\n",
        "        archivo.write(estado_deterministico)\n",
        "    print(f\"Se han creado el archivos en texto plano.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cuarta Parte:\n",
        "#### Esta parte nos permite ejecutar las funciones declaradas de manera adecuada, lo que generará el overview y el estado del caso a través de modelos de LLM, de esta manera se logra obtener los archivos pedidos en el apartado B. del entregable 1.\n",
        "####En este caso, el método final escogido para introducirle data al modelo fue la funcion IA1, debido a que su tiempo de proceso fue muchísimo más corto que el resto de funciones.  "
      ],
      "metadata": {
        "id": "gOxl7WRpttl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv64VsH8h7js"
      },
      "outputs": [],
      "source": [
        "rutaTexto = rutaTexto\n",
        "resumenPrompt= \"Haz un resumen porfavor\"\n",
        "estadoPrompt= \"Determina el estado del caso porfavor\"\n",
        "lista_carpetas= [carpeta for carpeta in os.listdir(rutaTexto) if os.path.isdir(os.path.join(rutaTexto, carpeta))]\n",
        "for carpeta in lista_carpetas:\n",
        "    ruta_carpeta= os.path.join(rutaTexto, carpeta)\n",
        "    lista_expedientes= [expediente for expediente in os.listdir(ruta_carpeta) if os.path.isdir(os.path.join(ruta_carpeta, expediente))]\n",
        "    for expediente in lista_expedientes:\n",
        "        ruta_expediente= os.path.join(ruta_carpeta, expediente)\n",
        "        caso_id, estado_deterministico = DeterminarID(expediente)\n",
        "        overview,estado = IA1(ruta_expediente,resumenPrompt,estadoPrompt)\n",
        "        Escritura(ruta_expediente,caso_id, overview, estado,estado_deterministico)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Código de Limpieza de Data\n",
        "\n",
        "#####El principal problema en la data, es que hay varios archivos PDF que contienen solamente imagenes, o que son escaneos de documentos en físico. Esto genera que el Código de Generación de Dataset genere archivos tipo .txt totalmente en blanco o en los cuales la mayoría de caracteres son espacios, lo que es indeseable.\n",
        "Por este motivo se ha realizado el codigo de limpieza, que elimina aquellos archivos cuya longitud sea 0, o si al menos el 50% de sus caracteres son espacios."
      ],
      "metadata": {
        "id": "VQFKbwZ_vKlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rutaTexto= rutaTexto\n",
        "\n",
        "lista_carpetas = [nombre for nombre in os.listdir(rutaTexto) if os.path.isdir(os.path.join(rutaTexto, nombre))]\n",
        "\n",
        "for carpeta in lista_carpetas:\n",
        "    ruta_carpeta=  os.path.join(rutaTexto,carpeta)\n",
        "    lista_expedientes= [carpeta for carpeta in os.listdir(ruta_carpeta) if os.path.isdir(os.path.join(ruta_carpeta, carpeta))]\n",
        "\n",
        "    for expediente in lista_expedientes:\n",
        "         ruta_expediente = os.path.join(ruta_carpeta,expediente)\n",
        "         lista_archivos= [nombre for nombre in os.listdir(ruta_expediente)]\n",
        "\n",
        "         for archivo in lista_archivos:\n",
        "              ruta_archivo = os.path.join(ruta_expediente,archivo)\n",
        "              if (ruta_archivo.lower().endswith('.txt')):\n",
        "                with open(ruta_archivo) as archivo:\n",
        "                            contenido = archivo.read()\n",
        "                espacios = sum(1 for c in contenido if c.isspace())\n",
        "                if len(contenido) == 0:\n",
        "                    os.remove(ruta_archivo)\n",
        "                elif (espacios / len(contenido) )>= 0.5 :\n",
        "                    os.remove(ruta_archivo)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vpf-hm-mwtqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código de Métrica Accuracy"
      ],
      "metadata": {
        "id": "klEelttwHwgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rutaTexto= rutaTexto\n",
        "\n",
        "lista_carpetas = [nombre for nombre in os.listdir(rutaTexto) if os.path.isdir(os.path.join(rutaTexto, nombre))]\n",
        "lista_estados= []\n",
        "lista_estados_deterministicos=[]\n",
        "\n",
        "for carpeta in lista_carpetas:\n",
        "    ruta_carpeta=  os.path.join(rutaTexto,carpeta)\n",
        "    lista_expedientes= [carpeta for carpeta in os.listdir(ruta_carpeta) if os.path.isdir(os.path.join(ruta_carpeta, carpeta))]\n",
        "\n",
        "    for expediente in lista_expedientes:\n",
        "         ruta_expediente = os.path.join(ruta_carpeta,expediente)\n",
        "         lista_IA= [nombre for nombre in os.listdir(ruta_expediente) if os.path.isdir(os.path.join(ruta_expediente, nombre))]\n",
        "\n",
        "         for nombre in lista_IA:\n",
        "            ruta_IA=  os.path.join(ruta_expediente,nombre)\n",
        "            lista_final = [nombre for nombre in os.listdir(ruta_IA) ]\n",
        "\n",
        "            for nombre in lista_final:\n",
        "                 ruta_final = os.path.join(ruta_IA,nombre)\n",
        "\n",
        "\n",
        "                 if ruta_final.lower().endswith('estado.txt'):\n",
        "                    with open(ruta_final, \"r\") as archivo:\n",
        "                            estado= archivo.read()\n",
        "                    lista_estados.append(estado)\n",
        "                 elif ruta_final.lower().endswith('estado_deterministico.txt'):\n",
        "                    with open(ruta_final, \"r\") as archivo:\n",
        "                            estado_deterministico= archivo.read()\n",
        "                    lista_estados_deterministicos.append(estado_deterministico)\n",
        "print(lista_estados)\n",
        "print(lista_estados_deterministicos)\n"
      ],
      "metadata": {
        "id": "MbV2k4QbH6FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Esta funcion es para corregir los casos deterministicos en caso haya un error de tipeo, se utiliza una lista con todos los estados posibles del caso\n",
        "def corregir_estado(estado, estados_validos):\n",
        "    matches = get_close_matches(estado, estados_validos)\n",
        "    if matches:\n",
        "        return matches[0]\n",
        "    else:\n",
        "        return estado\n",
        "\n",
        "estados_validos = [\n",
        "    \"RECHAZADO\",\n",
        "    \"INADMISIBLE\",\n",
        "    \"EJECUCION\",\n",
        "    \"TRAMITE\",\n",
        "    \"PLAZO DE IMPUGNACION\",\n",
        "    \"CALIFICACION\",\n",
        "    \"ARCHIVO DEFINITIVO\",\n",
        "    \"ADMITIDA\",\n",
        "    \"ATENDIDO\",\n",
        "    \"SENTENCIADO\",\n",
        "    \"RESUELTO\"\n",
        "]\n",
        "estados_deterministicos_corregidos = [corregir_estado(estado, estados_validos) for estado in lista_estados_deterministicos]\n",
        "print(estados_deterministicos_corregidos)\n",
        "#Ojo: resuelto atendido y sentenciado es el mismo estado, pero con diferente designacion."
      ],
      "metadata": {
        "id": "GYBlUb2CaSgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Esta funcion es para extraer solo el estado de toda la respuesta predicha por la IA, para versiones posteriores se considera utilizar esta funcion para generar el archivo de texto\n",
        "#En este caso no se utiliza, porque falta informacion acerca de TODOS los estados posibles existentes.\n",
        "def extraer_estado(cadena, estados_validos):\n",
        "    for estado in estados_validos:\n",
        "        if estado.lower()[:-1] in cadena.lower():\n",
        "            return estado\n",
        "    return cadena\n",
        "\n",
        "# Generar la lista de estados predichos2\n",
        "estados_predichos = [extraer_estado(estado, estados_validos) for estado in lista_estados]\n",
        "print(estados_predichos)"
      ],
      "metadata": {
        "id": "p9O3yAoTam8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ahora, ya con los estados extraidos y corregidos, cambiamos normalizamos los elementos resueltos, atendidos y sentenciados, por uno solo:\n",
        "i=0\n",
        "for elemento in estados_deterministicos_corregidos:\n",
        "  if elemento == 'ATENDIDO' or elemento == 'RESUELTO'\n",
        "    estados_deterministicos_corregidos[i]= 'SENTENCIADO'\n",
        "  i+=1\n",
        "\n",
        "i=0\n",
        "for elemento in estados_predichos:\n",
        "  if elemento == 'ATENDIDO' or elemento == 'RESUELTO'\n",
        "    estados_predichos[i]= 'SENTENCIADO'\n",
        "  i+=1\n"
      ],
      "metadata": {
        "id": "e77sAu98a9qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos la métrica de precisión.\n",
        "total_predicciones = len(lista_estados)\n",
        "predicciones_correctas = sum(1 for corr, pred in zip(estados_deterministicos_corregidos,estados_predichos) if corr == pred)\n",
        "precision = predicciones_correctas / total_predicciones\n",
        "\n",
        "# Imprimir la precisión\n",
        "print(f\"La precisión del modelo es: {precision:.2%}\")"
      ],
      "metadata": {
        "id": "obklcWFMaTs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#En esta parte, calculamos datos más específicos del modelo que podrían ayudarnos a saber cuales son los puntos débiles y fuertes.\n",
        "estados_validos2= [\n",
        "    \"RECHAZADO\",\n",
        "    \"INADMISIBLE\",\n",
        "    \"EJECUCION\",\n",
        "    \"TRAMITE\",\n",
        "    \"PLAZO DE IMPUGNACION\",\n",
        "    \"CALIFICACION\",\n",
        "    \"ARCHIVO DEFINITIVO\",\n",
        "    \"ADMITIDO\",\n",
        "    \"SENTENCIADO\"\n",
        "]\n",
        "\n",
        "# Realizar el análisis para cada estado\n",
        "for estado in estados_validos2:\n",
        "    estados_correctos_count = estados_deterministicos_corregidos.count(estado)\n",
        "    estados_predichos_count = estados_predichos.count(estado)\n",
        "    estados_correctamente_predichos = sum(1 for predicho in estados_predichos if predicho == estado and predicho in estados_deterministicos_corregidos)\n",
        "    no_estados_correctamente_predichos = sum(1 for predicho in estados_predichos if predicho == estado and predicho not in estados_deterministicos_corregidos)\n",
        "    print(f\"Para {estado}:\")\n",
        "    print(f\"La red neuronal predijo correctamente {estados_correctamente_predichos} estados {estado} de un total de {estados_correctos_count}.\")\n",
        "    print(f\"Además, detectó como {estado} {no_estados_correctamente_predichos} casos que no lo eran.\")"
      ],
      "metadata": {
        "id": "tHGwG-HQiVrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QgvDDdrnvaGW",
        "c00QBWpiqCWP",
        "6PRlbGW-rlko",
        "gWsdiO4ysd4f",
        "gOxl7WRpttl7"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}